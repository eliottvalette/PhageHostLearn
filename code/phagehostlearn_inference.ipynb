{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chronic-establishment",
   "metadata": {},
   "source": [
    "# PhageHostLearn.*klebsiella* - inference\n",
    "\n",
    "This notebook offers complete functionality to make predictions for new bacteria, phages or both, using a trained PhageHostLearn prediction model for Klebsiella phage-host interactions.\n",
    "\n",
    "**Overview of this notebook**\n",
    "1. Initial set-up\n",
    "2. Processing phage genomes and bacterial genomes into RBPs and K-locus proteins, respectively\n",
    "3. Computing feature representations based on ESM-2.\n",
    "4. Predicting new interactions and ranking\n",
    "\n",
    "**Architecture of the PhageHostLearn framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance) \n",
    "- Embeddings for both based on the ESM-2 language model.\n",
    "- An XGBoost model on top of language embeddings to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97849c",
   "metadata": {},
   "source": [
    "## 1. Initial set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf11f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data paths\n",
    "path = '/Users/eliottvalette/Documents/Clones/PhageHostLearn/data'\n",
    "phages_path = path + '/phages_genomes'\n",
    "bacteria_path = path + '/bacteria_genomes'\n",
    "pfam_path = '/Users/eliottvalette/Documents/Clones/PhageHostLearn/code/RBPdetect_phageRBPs.hmm'\n",
    "xgb_path = '/Users/eliottvalette/Documents/Clones/PhageHostLearn/code/RBPdetect_xgb_hmm.json'\n",
    "kaptive_db_path = path + '/Klebsiella_k_locus_primary_reference.gbk'\n",
    "suffix = 'inference'\n",
    "\n",
    "hmmer_path = path + '/hmmer-3.4'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60092310",
   "metadata": {},
   "source": [
    "## 2. Data processing\n",
    "\n",
    "The data processing of PhageHostLearn consists of four consecutive steps: (1) phage gene calling with PHANOTATE, (2) phage protein embedding with bio_embeddings, (3) phage RBP detection and (4) bacterial genome processing with Kaptive.\n",
    "\n",
    "Expected outputs: (1) an RBPbase.csv file with detected RBPs, (2) a Locibase.json file with detected K-loci proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cc090f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phagehostlearn_processing as phlp\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d633972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of phage files: 105\n",
      "Processing only the first  2  phages\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing phage genomes: 100%|██████████| 2/2 [00:16<00:00,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed PHANOTATE\n",
      "Number of phage genes: 145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# run Phanotate\n",
    "phanotate_path = '/Users/eliottvalette/Documents/Clones/PhageHostLearn/.venv/bin/phanotate.py'\n",
    "phlp.phanotate_processing(path, phages_path, phanotate_path, data_suffix=suffix, num_phages=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3839e659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All phage genomes processed\n"
     ]
    }
   ],
   "source": [
    "print('All phage genomes processed')\n",
    "time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62489ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBPbase already exists - skipping protein embeddings computation.\n"
     ]
    }
   ],
   "source": [
    "# Check if RBPbase already exists (if so, we can skip steps 2.2 and 2.3)\n",
    "rbpbase_path = os.path.join(path, f'RBPbase{suffix}.csv')\n",
    "rbpbase_path_fallback = os.path.join(path, 'RBPbase.csv')\n",
    "\n",
    "if os.path.exists(rbpbase_path) or os.path.exists(rbpbase_path_fallback):\n",
    "    print('RBPbase already exists - skipping protein embeddings computation.')\n",
    "else:\n",
    "    # Check for existing embeddings first\n",
    "    embeddings_path = os.path.join(path, f'phage_protein_embeddings{suffix}.csv')\n",
    "    embeddings_path_fallback = os.path.join(path, 'phage_protein_embeddings.csv')\n",
    "    \n",
    "    if os.path.exists(embeddings_path) or os.path.exists(embeddings_path_fallback):\n",
    "        print('Embedding file already exists. Skipping computation.')\n",
    "    else:\n",
    "        # run PTB embeddings (can be done faster in the cloud, see PTB_embeddings.ipynb)\n",
    "        phlp.compute_protein_embeddings(path, data_suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a69a6215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBPbase already exists - skipping PhageRBPdetect.\n"
     ]
    }
   ],
   "source": [
    "# Check if RBPbase already exists\n",
    "if os.path.exists(rbpbase_path) or os.path.exists(rbpbase_path_fallback):\n",
    "    print('RBPbase already exists - skipping PhageRBPdetect.')\n",
    "else:\n",
    "    # run PhageRBPdetect\n",
    "    gene_embeddings_file = os.path.join(path, f'phage_protein_embeddings{suffix}.csv')\n",
    "    gene_embeddings_file_fallback = os.path.join(path, 'phage_protein_embeddings.csv')\n",
    "    if not os.path.exists(gene_embeddings_file) and os.path.exists(gene_embeddings_file_fallback):\n",
    "        gene_embeddings_file = gene_embeddings_file_fallback\n",
    "    phlp.phageRBPdetect(path, pfam_path, hmmer_path, xgb_path, gene_embeddings_file, data_suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be319ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locibase already exists - skipping Kaptive processing.\n"
     ]
    }
   ],
   "source": [
    "# Check if Locibase already exists\n",
    "locibase_path = os.path.join(path, f'Locibase{suffix}.json')\n",
    "locibase_path_fallback = os.path.join(path, 'Locibase.json')\n",
    "\n",
    "if os.path.exists(locibase_path) or os.path.exists(locibase_path_fallback):\n",
    "    print('Locibase already exists - skipping Kaptive processing.')\n",
    "else:\n",
    "    # run Kaptive\n",
    "    phlp.process_bacterial_genomes(path, bacteria_path, kaptive_db_path, data_suffix=suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13771b",
   "metadata": {},
   "source": [
    "## 3. Feature construction\n",
    "\n",
    "Starts from the RBPbase.csv and the Locibase.json in the path. If the ESM-2 embeddings take too long, you might opt to do this step in the cloud or on a high-performance computer. Expected outputs: (1) a .csv file with RBP embeddings, (2) a .csv file with loci embeddings. The last function outputs the following Python objects: ESM-2 feature matrix and groups_bact. If the ESM-2 embeddings take too long, you might opt to do this step in the cloud or on a high-performance computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be94f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phagehostlearn_features as phlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34687caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing RBP embeddings file (without suffix): /Users/eliottvalette/Documents/Clones/PhageHostLearn/data/esm2_embeddings_rbp.csv\n",
      "Skipping ESM-2 embeddings computation for RBPs.\n"
     ]
    }
   ],
   "source": [
    "# ESM-2 features for RBPs\n",
    "rbp_embeddings_path = os.path.join(path, f'esm2_embeddings_rbp{suffix}.csv')\n",
    "rbp_embeddings_path_fallback = os.path.join(path, 'esm2_embeddings_rbp.csv')\n",
    "\n",
    "if os.path.exists(rbp_embeddings_path):\n",
    "    print(f'RBP embeddings file already exists at: {rbp_embeddings_path}')\n",
    "    print('Skipping ESM-2 embeddings computation for RBPs.')\n",
    "elif os.path.exists(rbp_embeddings_path_fallback):\n",
    "    print(f'Using existing RBP embeddings file (without suffix): {rbp_embeddings_path_fallback}')\n",
    "    print('Skipping ESM-2 embeddings computation for RBPs.')\n",
    "else:\n",
    "    phlf.compute_esm2_embeddings_rbp(path, data_suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94526a38",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using existing loci embeddings file (without suffix): /Users/eliottvalette/Documents/Clones/PhageHostLearn/data/esm2_embeddings_loci.csv\n",
      "Skipping ESM-2 embeddings computation for loci.\n"
     ]
    }
   ],
   "source": [
    "# ESM-2 features for loci\n",
    "loci_embeddings_path_check = os.path.join(path, f'esm2_embeddings_loci{suffix}.csv')\n",
    "loci_embeddings_path_fallback = os.path.join(path, 'esm2_embeddings_loci.csv')\n",
    "\n",
    "if os.path.exists(loci_embeddings_path_check):\n",
    "    print(f'Loci embeddings file already exists at: {loci_embeddings_path_check}')\n",
    "    print('Skipping ESM-2 embeddings computation for loci.')\n",
    "elif os.path.exists(loci_embeddings_path_fallback):\n",
    "    print(f'Using existing loci embeddings file (without suffix): {loci_embeddings_path_fallback}')\n",
    "    print('Skipping ESM-2 embeddings computation for loci.')\n",
    "else:\n",
    "    phlf.compute_esm2_embeddings_loci(path, data_suffix=suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdd9c807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions match? True\n"
     ]
    }
   ],
   "source": [
    "# Construct feature matrices\n",
    "# Use the paths already defined above, with fallback if suffixed files don't exist\n",
    "if not os.path.exists(rbp_embeddings_path):\n",
    "    rbp_embeddings_path = rbp_embeddings_path_fallback\n",
    "if not os.path.exists(loci_embeddings_path_check):\n",
    "    loci_embeddings_path = loci_embeddings_path_fallback\n",
    "else:\n",
    "    loci_embeddings_path = loci_embeddings_path_check\n",
    "\n",
    "features_esm2, groups_bact = phlf.construct_feature_matrices(path, suffix, loci_embeddings_path, rbp_embeddings_path, mode='test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83b57a",
   "metadata": {},
   "source": [
    "## 4. Predict and rank new interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05f9213",
   "metadata": {},
   "source": [
    "What we want is to make predictions per bacterium for all of the phages, and then use the prediction scores to rank the potential phages per bacterium."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "drawn-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the needed libraries\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "344d28a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliottvalette/Documents/Clones/PhageHostLearn/.venv/lib/python3.9/site-packages/xgboost/core.py:158: UserWarning: [17:51:54] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:872: Found JSON model saved before XGBoost 1.6, please save the model using current version again. The support for old JSON model will be discontinued in XGBoost 2.3.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the XGBoost model and make predictions\n",
    "xgb = XGBClassifier()\n",
    "xgb.load_model('phagehostlearn_esm2_xgb.json')\n",
    "scores_xgb = xgb.predict_proba(features_esm2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d51249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prediction scores in an interaction matrix\n",
    "groups_bact = np.asarray(groups_bact)\n",
    "loci_embeddings = pd.read_csv(loci_embeddings_path)\n",
    "rbp_embeddings = pd.read_csv(rbp_embeddings_path)\n",
    "bacteria = list(loci_embeddings['accession'])\n",
    "phages = list(set(rbp_embeddings['phage_ID']))\n",
    "\n",
    "score_matrix = np.zeros((len(bacteria), len(phages)))\n",
    "for i, group in enumerate(list(set(groups_bact))):\n",
    "    #scores_this_group = scores[groups_bact == group]\n",
    "    scores_this_group = scores_xgb[groups_bact == group]\n",
    "    score_matrix[i, :] = scores_this_group\n",
    "results = pd.DataFrame(score_matrix, index=bacteria, columns=phages)\n",
    "results.to_csv(path+'/prediction_results'+suffix+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a08f973f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rank the phages per bacterium\n",
    "ranked = {}\n",
    "for group in list(set(groups_bact)):\n",
    "    scores_this_group = scores_xgb[groups_bact == group]\n",
    "    ranked_phages = [(x, y) for y, x in sorted(zip(scores_this_group, phages), reverse=True)]\n",
    "    ranked[bacteria[group]] = ranked_phages\n",
    "\n",
    "# save results\n",
    "with open(path+'/ranked_results'+suffix+'.pickle', 'wb') as f:\n",
    "    pickle.dump(ranked, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036206be",
   "metadata": {},
   "source": [
    "## 5. Read & interpret results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "139793ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "with open(path+'/ranked_results'+suffix+'.pickle', 'rb') as f:\n",
    "    ranked_results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b7c9583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KP_HGUA02_071</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205KP-HG</th>\n",
       "      <td>0.065</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52KP-HG</th>\n",
       "      <td>0.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kpcas042</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGUA4_08</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGV2C_28</th>\n",
       "      <td>0.999</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HGV2C_36_contigs</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.990</td>\n",
       "      <td>0.809</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NTUH</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.999</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0.947</td>\n",
       "      <td>0.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CU451</th>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.501</td>\n",
       "      <td>0.313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KP_HGUA03_147</th>\n",
       "      <td>0.998</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.964</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0      1      2      3      4\n",
       "KP_HGUA02_071     1.000  1.000  0.999  0.998  0.975\n",
       "205KP-HG          0.065  0.065  0.021  0.004  0.003\n",
       "52KP-HG           0.001  0.000  0.000  0.000  0.000\n",
       "Kpcas042          1.000  1.000  1.000  0.985  0.961\n",
       "HGUA4_08          0.999  0.095  0.024  0.007  0.003\n",
       "...                 ...    ...    ...    ...    ...\n",
       "HGV2C_28          0.999  0.234  0.088  0.075  0.022\n",
       "HGV2C_36_contigs  1.000  0.990  0.809  0.015  0.007\n",
       "NTUH              1.000  0.999  0.998  0.947  0.087\n",
       "CU451             1.000  1.000  1.000  0.501  0.313\n",
       "KP_HGUA03_147     0.998  0.992  0.989  0.964  0.005\n",
       "\n",
       "[200 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print top phages per bacterium\n",
    "top =  5\n",
    "scores = np.zeros((len(ranked_results.keys()), top))\n",
    "for i, acc in enumerate(ranked_results.keys()):\n",
    "    topscores = [round(y, 3) for (x,y) in ranked_results[acc]][:top]\n",
    "    scores[i,:] = topscores\n",
    "pd.DataFrame(scores, index=list(ranked_results.keys()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
