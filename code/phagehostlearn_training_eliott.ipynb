{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "chronic-establishment",
   "metadata": {},
   "source": [
    "# PhageHostLearn - v3.4.klebsiella - training\n",
    "\n",
    "An AI-based Phage-Host interaction predictor framework with K-loci and receptor-binding proteins at its core. This particular PhageHostLearn is for *Klebsiella pneumoniae* related phages. \n",
    "\n",
    "This notebook offers complete functionality to train a PhageHostLearn prediction model for Klebsiella phages starting from phage genomes, bacterial genomes and a matrix of known interactions.\n",
    "\n",
    "**Overview of this notebook**\n",
    "1. Initial set-up\n",
    "2. Processing phage genomes and bacterial genomes into RBPs and K-locus proteins, respectively\n",
    "3. Computing feature representations based on ESM-2\n",
    "4. Training and evaluating the machine learning model\n",
    "\n",
    "**Architecture of the PhageHostLearn framework**: \n",
    "- Multi-RBP setting: phages consisting of one or more RBPs (multi-instance)\n",
    "- K-loci proteins (multi-instance) \n",
    "- Embeddings for both based on the ESM-2 language model\n",
    "- An XGBoost model on top of the ESM-2 embeddings to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e97849c",
   "metadata": {},
   "source": [
    "## 1. Initial set-up"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cf6121",
   "metadata": {},
   "source": [
    "PhageHostLearn takes as inputs phage genomes and bacterial genomes that are later transformed into phage RBPs and bacterial K-locus proteins. If you want to train a prediction model from scratch on phage and bacterial genomes, start from this step. If you want to reproduce our analyses from the processed RBPs and K-loci proteins in our Zenodo repository, go to `3. Feature construction`.\n",
    "\n",
    "To do the data processing, you'll need to do the following:\n",
    "1. Set up a folder for all the data that will be stored and generated by PhageHostLearn. Write the path to this folder in the code block below for 'general_path'.\n",
    "2. In the folder, create two subfolders for the phage genomes and bacterial genomes (one for phage genomes and one for bacterial genomes). Collect both phage genomes and bacterial genomes as individual FASTA files and store them in the two separate folders.\n",
    "3. Install [PHANOTATE](https://github.com/deprekate/PHANOTATE) and [Kaptive](https://github.com/katholt/Kaptive), both of which you'll need to process the phage and bacterial genomes. Locate PHANOTATE and write the path under the 2.1 code block below. Alternatively, copy the PHANOTATE file into your general folder. In addition, from the Kaptive repository, copy the .gbk databases into the general data folder.\n",
    "4. Optionally install [bio_embeddings](https://github.com/sacdallago/bio_embeddings) to locally compute protein embeddings needed for RBP detection or opt do do this step in the cloud for faster results (see instructions below).\n",
    "5. Install [fair-esm](https://github.com/facebookresearch/esm) to compute ESM-2 embeddings for the PhageHostLearn interaction prediction models.\n",
    "6. Store the known interactions between phages and bacteria in an .xlsx file in which the first column is used for bacterial genome names and the first row is used for phage genome names. The names should correspond to the FASTA files in the respective folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf11f468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "general_path = os.path.join(project_root, 'data')\n",
    "results_path = os.path.join(project_root, 'results')\n",
    "data_suffix = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60092310",
   "metadata": {},
   "source": [
    "## 2. Data processing\n",
    "\n",
    "The data processing of PhageHostLearn consists of five consecutive steps: (1) phage gene calling with PHANOTATE, (2) phage protein embedding with bio_embeddings, (3) phage RBP detection, (4) bacterial genome processing with Kaptive and (5) processing the interaction matrix.\n",
    "\n",
    "Expected outputs: (1) an RBPbase.csv file with detected RBPs, (2) a Locibase.json file with detected K-loci proteins, (3) a .csv file of processed interaction data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cc090f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliottvalette/Documents/Clones/PhageHostLearn/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import phagehostlearn_processing as phlp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b686db",
   "metadata": {},
   "source": [
    "#### 2.1 PHANOTATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d633972",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m phage_genomes_path \u001b[38;5;241m=\u001b[39m general_path\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/phages_genomes\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m phanotate_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/opt/homebrew/Caskroom/miniforge/base/envs/ML1/bin/phanotate.py\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mphlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mphanotate_processing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgeneral_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphage_genomes_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mphanotate_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_suffix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_suffix\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Clones/PhageHostLearn/code/phagehostlearn_processing.py:238\u001b[0m, in \u001b[0;36mphanotate_processing\u001b[0;34m(general_path, phage_genomes_path, phanotate_path, data_suffix, add, test)\u001b[0m\n\u001b[1;32m    236\u001b[0m     phage_files \u001b[38;5;241m=\u001b[39m [x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m phage_files \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.fasta\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m phage_ids]\n\u001b[1;32m    237\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28mlen\u001b[39m(phage_files), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m more phages (add=True)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 238\u001b[0m bar \u001b[38;5;241m=\u001b[39m \u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mphage_files\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mleave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m name_list \u001b[38;5;241m=\u001b[39m []; gene_list \u001b[38;5;241m=\u001b[39m []; gene_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m phage_files:\n",
      "File \u001b[0;32m~/Documents/Clones/PhageHostLearn/.venv/lib/python3.9/site-packages/tqdm/notebook.py:234\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m unit_scale \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munit_scale \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    233\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;241m*\u001b[39m unit_scale \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtotal\n\u001b[0;32m--> 234\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_printer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mncols\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontainer\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m proxy(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisplayed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/Clones/PhageHostLearn/.venv/lib/python3.9/site-packages/tqdm/notebook.py:108\u001b[0m, in \u001b[0;36mtqdm_notebook.status_printer\u001b[0;34m(_, total, desc, ncols)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Fallback to text bar if there's no total\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# DEPRECATED: replaced with an 'info' style bar\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# if not total:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    105\u001b[0m \n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# Prepare IPython progress bar\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m IProgress \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# #187 #451 #558 #872\u001b[39;00m\n\u001b[0;32m--> 108\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(WARN_NOIPYW)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m total:\n\u001b[1;32m    110\u001b[0m     pbar \u001b[38;5;241m=\u001b[39m IProgress(\u001b[38;5;28mmin\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mmax\u001b[39m\u001b[38;5;241m=\u001b[39mtotal)\n",
      "\u001b[0;31mImportError\u001b[0m: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html"
     ]
    }
   ],
   "source": [
    "phage_genomes_path = general_path+'/phages_genomes'\n",
    "phanotate_path = '/opt/homebrew/Caskroom/miniforge/base/envs/ML1/bin/phanotate.py'\n",
    "phlp.phanotate_processing(general_path, phage_genomes_path, phanotate_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a48369",
   "metadata": {},
   "source": [
    "#### 2.2 Protein embeddings\n",
    "\n",
    "The code block below computes protein embeddings for all of the detected phage genes (translated to proteins) using the bio_embeddings package (see `1. Initial set-up`). This might take a while on CPU. Alternatively, you can run this step in Google Colab or on Kaggle using the 'compute_embeddings_cloud.ipynb', which does exactly the same thing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62489ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlp.compute_protein_embeddings(general_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd07fe07",
   "metadata": {},
   "source": [
    "#### 2.3 PhageRBPdetect\n",
    "\n",
    "Either copy the `RBPdetect_phageRBPs.hmm` and `RBPdetect_xgb_hmm.json` files into the general data folder, or provide their absolute paths in the code block below, and then run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69a6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "pfam_path = general_path+'/RBPdetect_phageRBPs.hmm'\n",
    "hmmer_path = '/Users/Dimi/hmmer-3.3.1'\n",
    "xgb_path = general_path+'/RBPdetect_xgb_hmm.json'\n",
    "gene_embeddings_path = general_path+'/phage_protein_embeddings'+data_suffix+'.csv'\n",
    "phlp.phageRBPdetect(general_path, pfam_path, hmmer_path, xgb_path, gene_embeddings_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ed4b0c",
   "metadata": {},
   "source": [
    "#### 2.4 Kaptive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be319ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bact_genomes_path = general_path+'/klebsiella_genomes/fasta_files'\n",
    "kaptive_database_path = general_path+'/Klebsiella_k_locus_primary_reference.gbk'\n",
    "phlp.process_bacterial_genomes(general_path, bact_genomes_path, kaptive_database_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b59d1d1",
   "metadata": {},
   "source": [
    "#### 2.5 Process the interaction matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff86e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactions_xlsx_path = general_path+'/klebsiella_phage_host_interactions.xlsx'\n",
    "phlp.process_interactions(general_path, interactions_xlsx_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6915feb3",
   "metadata": {},
   "source": [
    "If you want to combine separate data sources of interactions, you can use the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f66064",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = general_path+'/phage_host_interactions'+data_suffix\n",
    "new_file = general_path+'/klebsiella_interactions_part2.xlsx' # part 2\n",
    "phlp.add_to_database(output+'.csv', new_file, output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e13771b",
   "metadata": {},
   "source": [
    "## 3. Feature construction\n",
    "\n",
    "Starts from the RBPbase.csv and the Locibase.json files that should be stored in the general_path. If you wish to reproduce our analyses, you can download these files from our [Zenodo repository](https://doi.org/10.5281/zenodo.8095914).\n",
    "\n",
    "Expected outputs: (1) a .csv file with RBP embeddings, (2) a .csv file with loci embeddings. The last function outputs the following Python objects: ESM-2 feature matrix, labels, groups_loci and groups_phage (for evaluation). If the ESM-2 embeddings take too long, you might opt to do this step in the cloud or on a high-performance computer.\n",
    "\n",
    "If you're retraining a model with the same data but new validated interactions, you can simply run the `construct_feature_matrices` function to construct updated feature matrices and labels and train models anew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be94f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phagehostlearn_features as phlf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34687caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlf.compute_esm2_embeddings_rbp(general_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94526a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "phlf.compute_esm2_embeddings_loci(general_path, data_suffix=data_suffix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af80705",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_embeddings_path = general_path+'/esm2_embeddings_rbp'+data_suffix+'.csv'\n",
    "loci_embeddings_path = general_path+'/esm2_embeddings_loci'+data_suffix+'.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f97b36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_esm2, labels, groups_loci, groups_phage = phlf.construct_feature_matrices(general_path, \n",
    "                                                                            data_suffix, loci_embeddings_path, \n",
    "                                                                            rbp_embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be83b57a",
   "metadata": {},
   "source": [
    "## 4. Training and evaluating models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "drawn-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import phagehostlearn_utils as phlu\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.metrics import roc_auc_score, auc, precision_recall_curve, roc_curve\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416719a1",
   "metadata": {},
   "source": [
    "#### 4.1 Training both models and saving them for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344d28a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpus=6\n",
    "labels = np.asarray(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647d23ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESM-2 FEATURES + XGBoost model\n",
    "imbalance = sum([1 for i in labels if i==1]) / sum([1 for i in labels if i==0])\n",
    "xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.3, n_estimators=250, max_depth=7,\n",
    "                    n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "xgb.fit(features_esm2, labels)\n",
    "xgb.save_model('phagehostlearn_vbeta.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c0143c",
   "metadata": {},
   "source": [
    "#### 4.2 LOGOCV with the combined model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da198e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we want to set a threshold for grouping\n",
    "matrix = np.loadtxt(general_path+'/all_loci_score_matrix.txt', delimiter='\\t')\n",
    "threshold = 0.995\n",
    "threshold_str='995'\n",
    "group_i = 0\n",
    "new_groups = [np.nan] * len(groups_loci)\n",
    "for i in range(matrix.shape[0]):\n",
    "    cluster = np.where(matrix[i,:] >= threshold)[0]\n",
    "    oldgroups_i = [k for k, x in enumerate(groups_loci) if x in cluster]\n",
    "    if np.isnan(new_groups[groups_loci.index(i)]):\n",
    "        for ogi in oldgroups_i:\n",
    "            new_groups[ogi] = group_i\n",
    "        group_i += 1\n",
    "groups_loci = new_groups\n",
    "print('Number of unique groups: ', len(set(groups_loci)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4aad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "logo = LeaveOneGroupOut()\n",
    "cpus = 6\n",
    "scores_lan = []\n",
    "label_list = []\n",
    "labels = np.asarray(labels)\n",
    "pbar = tqdm(total=len(set(groups_loci)))\n",
    "for train_index, test_index in logo.split(features_esm2, labels, groups_loci):\n",
    "    #print(test_index)\n",
    "    # get the training and test data\n",
    "    Xlan_train, Xlan_test = features_esm2[train_index], features_esm2[test_index]\n",
    "    y_train, y_test = labels[train_index], labels[test_index]\n",
    "    imbalance = sum([1 for i in y_train if i==1]) / sum([1 for i in y_train if i==0])\n",
    "\n",
    "    ## ESM-2 EMBEDDINGS: XGBoost model\n",
    "    xgb = XGBClassifier(scale_pos_weight=1/imbalance, learning_rate=0.3, n_estimators=250, max_depth=7,\n",
    "                        n_jobs=cpus, eval_metric='logloss', use_label_encoder=False)\n",
    "    xgb.fit(Xlan_train, y_train)\n",
    "    score_xgb = xgb.predict_proba(Xlan_test)[:,1]\n",
    "    scores_lan.append(score_xgb)\n",
    "    \n",
    "    # save labels for later\n",
    "    label_list.append(y_test)\n",
    "    \n",
    "    # pbar update\n",
    "    pbar.update(1)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb9f59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "logo_results = {'labels': label_list, 'scores_language': scores_lan}   \n",
    "with open(results_path+'/v3.4/combined_logocv_results_v34_'+threshold_str+'.pickle', 'wb') as f:\n",
    "    pickle.dump(logo_results, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1748536a",
   "metadata": {},
   "source": [
    "## 5. Results interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "with open(results_path+'/v3.4/combined_logocv_results_v34_'+threshold_str+'.pickle', 'rb') as f:\n",
    "    logo_results = pickle.load(f)\n",
    "scores_lan = logo_results['scores_language']\n",
    "label_list = logo_results['labels']\n",
    "\n",
    "# compute performance\n",
    "rqueries_lan = []\n",
    "for i in range(len(set(groups_loci))):\n",
    "    score_lan = scores_lan[i]\n",
    "    y_test = label_list[i]\n",
    "    try:\n",
    "            roc_auc = roc_auc_score(y_test, score_lan)\n",
    "            ranked_lan = [x for _, x in sorted(zip(score_lan, y_test), reverse=True)]\n",
    "            rqueries_lan.append(ranked_lan)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8f6035",
   "metadata": {},
   "source": [
    "#### ROC AUC curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, ROC AUC \n",
    "labels = np.concatenate(label_list).ravel()\n",
    "scoreslr = np.concatenate(scores_lan).ravel()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "fpr, tpr, thrs = roc_curve(labels, scoreslr)\n",
    "rauclr = round(auc(fpr, tpr), 3)\n",
    "ax.plot(fpr, tpr, c='#124559', linewidth=2.5, label='ESM-2 + XGBoost (AUC= '+str(rauclr)+')')\n",
    "ax.set_xlabel('False positive rate', size=24)\n",
    "ax.set_ylabel('True positive rate', size=24)\n",
    "ax.legend(loc=4, prop={'size': 20})\n",
    "ax.grid(True, linestyle=':')\n",
    "ax.yaxis.set_tick_params(labelsize = 14)\n",
    "ax.xaxis.set_tick_params(labelsize = 14)\n",
    "fig.savefig(results_path+'/vbeta/logocv_rocauc.png', dpi=400)\n",
    "fig.savefig(results_path+'/vbeta/logocv_rocauc_svg.svg', format='svg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13828f4a",
   "metadata": {},
   "source": [
    "#### Hit ratio against microbiologist approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94dce071",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "\n",
    "# prep the data\n",
    "interactions1 = general_path+'/klebsiella_phage_host_interactions.xlsx'\n",
    "interactions2 = general_path+'/klebsiella_interactions_part2.xlsx' # for part 1 NO SUGGESTIONS POSSIBLE -> ALL UNIQUE K-TYPES\n",
    "matrix1 = pd.read_excel(interactions1, index_col=0, header=0)\n",
    "matrix2 = pd.read_excel(interactions2, index_col=0, header=0)\n",
    "locipath = general_path+'/LocibaseValencia.json'\n",
    "seros = pd.read_csv(general_path+'/serotypesValencia.csv')\n",
    "with open(locipath) as f:\n",
    "    locibase = json.load(f)\n",
    "\n",
    "# do the informed approach\n",
    "hits = {i: 0 for i in range(1, 51)}\n",
    "total = 0\n",
    "# --------------------\n",
    "# MATRIX 1\n",
    "# --------------------\n",
    "loci_serotype = {}\n",
    "for i, accession in enumerate(locibase.keys()):\n",
    "    loci_serotype[accession] = seros['sero'][i]\n",
    "    \n",
    "# phages sorted by broad-spec\n",
    "sorted_phages = matrix1.sum().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# delete keys not in this matrix (only suggestions within the matrix)\n",
    "rownames = list(matrix1.index.values)\n",
    "no_genome = ['K2', 'K21', 'K23', 'K27', 'K28', 'K40', 'K45', 'K48', 'K52', 'K53', 'K67', 'K69', 'K70', 'K71', 'K72']\n",
    "rownames = [str(i) for i in rownames if i not in no_genome]\n",
    "for key in list(loci_serotype.keys()):\n",
    "    if key not in rownames:\n",
    "        del loci_serotype[key]\n",
    "        \n",
    "# iterate over all accessions in matrix1\n",
    "for i, accession in enumerate(rownames):\n",
    "    # only compute hit ratio when we can find something\n",
    "    if sum(matrix1.loc[accession]) > 0:\n",
    "        # get the serotype\n",
    "        serotype = loci_serotype[str(accession)]\n",
    "        # search other bacteria with the same serotype\n",
    "        same_serotype = [key for key, value in loci_serotype.items() if value == serotype]\n",
    "        same_serotype.remove(str(accession))\n",
    "        # get phage suggestions: columnnames of corresponding bacteria in matrix1 with value = 1\n",
    "        phage_suggestions = []\n",
    "        for j, acc in enumerate(same_serotype):\n",
    "            if acc in ['132', '779', '806', '228', '245', '406', '1210', '1446', '1468', '1572', '2164']:\n",
    "                acc = int(acc)\n",
    "            colnames = matrix1.columns[matrix1.loc[acc] == 1].tolist()\n",
    "            phage_suggestions.append(colnames)\n",
    "        # flatten the list\n",
    "        phage_suggestions = list(set([item for sublist in phage_suggestions for item in sublist]))\n",
    "        # sort the list based: most narrow phages first!\n",
    "        phage_suggestions.sort(key=lambda x: matrix1[x].sum(), reverse=True)\n",
    "        \n",
    "        total += 1\n",
    "        for k in range(1, 51):\n",
    "            # approach 1: if we dont have enough suggestions, pick extra at random from total pool available\n",
    "            # approach 2: now, we supplement them with the sorted phages by broad-spectrum, not random!\n",
    "            if k > len(phage_suggestions):\n",
    "                sample_pool = [sugg for sugg in sorted_phages if sugg not in phage_suggestions]\n",
    "                to_pick = k-len(phage_suggestions)\n",
    "                if len(sample_pool) < to_pick:\n",
    "                    phage_suggestions = phage_suggestions + sample_pool\n",
    "                else:\n",
    "                    phage_suggestions = phage_suggestions + sample_pool[:to_pick]\n",
    "\n",
    "            #suggested = random.sample(phage_suggestions, k)\n",
    "            if any([matrix1.loc[accession, sugg] == 1 for sugg in phage_suggestions]):\n",
    "                hits[k] += 1\n",
    "                \n",
    "# --------------------\n",
    "# MATRIX 2\n",
    "# --------------------\n",
    "hits2 = {i: 0 for i in range(1, 51)}\n",
    "total2 = 0\n",
    "loci_serotype = {}\n",
    "for i, accession in enumerate(locibase.keys()):\n",
    "    loci_serotype[accession] = seros['sero'][i]\n",
    "    \n",
    "sorted_phages = matrix2.sum().sort_values(ascending=False).index.tolist()\n",
    "\n",
    "# delete keys not in this matrix (only suggestions within the matrix)\n",
    "rownames = list(matrix2.index.values)\n",
    "rownames = [str(i) for i in rownames]\n",
    "for key in list(loci_serotype.keys()):\n",
    "    if key not in rownames:\n",
    "        del loci_serotype[key]\n",
    "\n",
    "# iterate over all accessions in matrix2\n",
    "for i, accession in enumerate(matrix2.index.values):\n",
    "    # only compute hit ratio when we can find something\n",
    "    if sum(matrix2.loc[accession]) > 0:\n",
    "        # get the serotype\n",
    "        serotype = loci_serotype[str(accession)]\n",
    "        # search other bacteria with the same serotype\n",
    "        same_serotype = [key for key, value in loci_serotype.items() if value == serotype]\n",
    "        same_serotype.remove(str(accession))\n",
    "        # get phage suggestions: columnnames of corresponding bacteria in matrix2 with value = 1\n",
    "        phage_suggestions = []\n",
    "        for j, acc in enumerate(same_serotype):\n",
    "            if acc in ['132', '779', '806', '228', '245', '406', '1210', '1446', '1468', '1572', '2164']:\n",
    "                acc = int(acc)\n",
    "            colnames = matrix2.columns[matrix2.loc[acc] == 1].tolist()\n",
    "            phage_suggestions.append(colnames)\n",
    "        # flatten the list\n",
    "        phage_suggestions = list(set([item for sublist in phage_suggestions for item in sublist]))\n",
    "        # sort the list based: most narrow phages first!\n",
    "        phage_suggestions.sort(key=lambda x: matrix2[x].sum(), reverse=True)\n",
    "\n",
    "        total += 1\n",
    "        total2 += 1\n",
    "        for k in range(1, 51):\n",
    "            # if we dont have enough suggestions, pick extra at random from the total pool\n",
    "            if k > len(phage_suggestions):\n",
    "                sample_pool = [sugg for sugg in sorted_phages if sugg not in phage_suggestions]\n",
    "                to_pick = k-len(phage_suggestions)\n",
    "                if len(sample_pool) < to_pick:\n",
    "                    phage_suggestions = phage_suggestions + sample_pool\n",
    "                else:\n",
    "                    phage_suggestions = phage_suggestions + sample_pool[:to_pick]\n",
    "            \n",
    "            if any([matrix2.loc[accession, sugg] == 1 for sugg in phage_suggestions]):\n",
    "                hits[k] += 1\n",
    "                hits2[k] += 1\n",
    "\n",
    "informed_hitratio = {k: v/total for k, v in hits.items()}\n",
    "informed_hitratio2 = {k: v/total2 for k, v in hits2.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd02253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results, hit ratios @ K\n",
    "ks = np.linspace(1, 50, 50)\n",
    "hits_lan = [phlu.hitratio(rqueries_lan, int(k)) for k in ks]\n",
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.plot(ks, hits_lan, c='#124559', linewidth=2.5, label='ESM-2 + XGBoost')\n",
    "#ax.plot(ks, hits_ens, c='#124559', linewidth=2.5, label='Combined model')\n",
    "#ax.plot(ks, hits_random, c='#81B29A', linewidth=2.5, ls=':', label='Random guess')\n",
    "#ax.plot(ks, list(informed_hitratio.values()), c='#E15554', linewidth=2.5, ls='-.', label='Informed microbiologist')\n",
    "#ax.plot(ks, list(informed_hitratio2.values()), c='#E15554', linewidth=2.5, ls=':', label='Informed guess (Bea only)')\n",
    "ax.set_xlabel('$\\it{k}$', size=24)\n",
    "ax.set_ylabel('Hit ratio @ $\\it{k}$', size=24)\n",
    "ax.set_ylim(0.1, 1)\n",
    "ax.legend(loc=4, prop={'size': 24})\n",
    "ax.grid(True, linestyle=':')\n",
    "ax.yaxis.set_tick_params(labelsize = 14)\n",
    "ax.xaxis.set_tick_params(labelsize = 14)\n",
    "fig.savefig(results_path+'/vbeta/logocv_hitratio_informed.png', dpi=400)\n",
    "fig.savefig(results_path+'/vbeta/logocv_hitratio_informed_svg.svg', format='svg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899e1da9",
   "metadata": {},
   "source": [
    "#### Performance per K-type\n",
    "\n",
    "https://medium.com/@curryrowan/simplified-logistic-regression-classification-with-categorical-variables-in-python-1ce50c4b137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb8ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read results\n",
    "with open(results_path+'/v3.4/combined_logocv_results_v34_100.pickle', 'rb') as f:\n",
    "    logo_results = pickle.load(f)\n",
    "scores_lan = logo_results['scores_language']\n",
    "label_list = logo_results['labels']\n",
    "\n",
    "# read K-types\n",
    "seros = pd.read_csv(general_path+'/serotypesValencia.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean hit ratio per K-type\n",
    "unique_seros = list(set(seros['sero']))\n",
    "performance_ktypes = {}\n",
    "labelcount_ktypes = {}\n",
    "for unique in unique_seros:\n",
    "    indices = seros['sero'] == unique\n",
    "    subscores_lan = [val for is_good, val in zip(indices, scores_lan) if is_good]\n",
    "    sublabels = [val for is_good, val in zip(indices, label_list) if is_good]\n",
    "    labelcount_ktypes[unique] = [sum(i) for i in sublabels]\n",
    "    rqueries_lan = []\n",
    "    for i in range(len(subscores_lan)):\n",
    "        score_lan = subscores_lan[i]\n",
    "        y_test = sublabels[i]\n",
    "        if sum(y_test) > 0:\n",
    "            ranked_lan = [x for _, x in sorted(zip(score_lan, y_test), reverse=True)]\n",
    "            rqueries_lan.append(ranked_lan)\n",
    "    if len(rqueries_lan) > 0:\n",
    "        hr_lan = round(phlu.hitratio(rqueries_lan, 10), 3)\n",
    "        performance_ktypes[unique] = [('HR_XGB', hr_lan)]\n",
    "    #else:\n",
    "    #    performance_ktypes[unique] = [('MAR_XGB', np.nan), ('MAR_HDC', np.nan), ('MAR_COMBINED', np.nan)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c524e6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_hr_xgb = []\n",
    "for ktype in performance_ktypes:\n",
    "    performance_hr_xgb.append(performance_ktypes[ktype][0][1])\n",
    "sortedpairs = [(x,y) for y, x in sorted(zip(performance_hr_xgb, list(performance_ktypes.keys())), reverse=True)]\n",
    "fig, ax = plt.subplots(figsize=(16,6))\n",
    "ax.hist(performance_hr_xgb, bins=25, color='#124559')\n",
    "#sns.barplot(x=[score for (key, score) in sortedpairs], y=[key for (key, score) in sortedpairs], ax=ax, palette='magma')\n",
    "ax.set_xlabel('Mean top-10 hit ratio', size=22)\n",
    "ax.set_ylabel('Number of K-types', size=22)\n",
    "ax.yaxis.set_tick_params(labelsize = 14)\n",
    "ax.xaxis.set_tick_params(labelsize = 14)\n",
    "fig.tight_layout()\n",
    "fig.savefig(results_path+'/vbeta/histogram_ktypes_svg.svg', format='svg', dpi=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf0916",
   "metadata": {},
   "source": [
    "#### Hit ratio per K-type versus number of pos labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e921059",
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = [x[0] for x in sortedpairs if x[1] == 1] # all with HR == 1\n",
    "bottom10 = [x[0] for x in sortedpairs if x[1] == 0] # all with HR == 0\n",
    "middle = [x[0] for x in sortedpairs if (x[1] != 0 and x[1] != 1)]\n",
    "countst10 = []\n",
    "countsb10 = []\n",
    "countsmid = []\n",
    "for key in labelcount_ktypes.keys():\n",
    "    if key in top10:\n",
    "        countst10.append(labelcount_ktypes[key])\n",
    "    elif key in bottom10:\n",
    "        countsb10.append(labelcount_ktypes[key])\n",
    "    elif key in middle:\n",
    "        countsmid.append(labelcount_ktypes[key])\n",
    "countst10 = [i for x in countst10 for i in x]\n",
    "countsb10 = [i for x in countsb10 for i in x]\n",
    "countsmid = [i for x in countsmid for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d562d",
   "metadata": {},
   "outputs": [],
   "source": [
    "countlist = [countst10, countsmid, countsb10]\n",
    "binlist = [15, 15, 15]\n",
    "\n",
    "for i, count in enumerate(countlist):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.histplot(count, ax=ax, color='#221150', bins=binlist[i])\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_xlabel('Number of confirmed interactions', size=22)\n",
    "    ax.set_ylabel('Number of bacteria', size=22)\n",
    "    ax.yaxis.set_tick_params(labelsize = 14)\n",
    "    ax.xaxis.set_tick_params(labelsize = 14)\n",
    "    fig.savefig(results_path+'/v3.4/ktypecounts_svg'+str(i)+'.svg', format='svg', dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
